{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aef0c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.11 s\n",
      "Wall time: 5.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Imports:\n",
    "\n",
    "# defaults\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# torch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, NAdam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# UNet dependencies\n",
    "from denoising_diffusion_pytorch import Unet1D # basic unet for unconditioned\n",
    "# from functools import partial\n",
    "# from einops import rearrange, reduce\n",
    "# from einops.layers.torch import Rearrange\n",
    "\n",
    "# Smact check dependencies\n",
    "import smact\n",
    "from smact.screening import pauling_test\n",
    "import pandas\n",
    "import itertools\n",
    "from fractions import Fraction\n",
    "import functools\n",
    "from pymatgen.core.composition import Composition\n",
    "\n",
    "# Typenotes\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "\n",
    "# file import\n",
    "from helper_formula_parse import *\n",
    "from supercon_wtypes_parse import *\n",
    "from helper_dataset_shuffle import *\n",
    "from dataset_creation import *\n",
    "from helper_reverse_formula import *\n",
    "# from helper_unet_functions import *\n",
    "from smact_validity_checks import *\n",
    "from save_valid_compounds_to_csv import *\n",
    "# from unet1d import * - own UNet for later Few-shot diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f10a70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Correct element table length.\n",
      "NOTE: Valid table.\n"
     ]
    }
   ],
   "source": [
    "SUPERCON_DATA_FILE = \"SuperCon_with_types.dat\"\n",
    "\n",
    "# element table to set up vectors in R^(1x96): must len(element_table) = 96\n",
    "element_table = [\"H\",\"He\",\"Li\",\"Be\",\"B\",\"C\",\"N\",\"O\",\"F\",\"Ne\",\"Na\",\"Mg\",\"Al\",\"Si\",\"P\",\"S\",\"Cl\",\"Ar\",\"K\",\"Ca\",\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Fe\",\"Co\",\n",
    "              \"Ni\",\"Cu\",\"Zn\",\"Ga\",\"Ge\",\"As\",\"Se\",\"Br\",\"Kr\",\"Rb\",\"Sr\",\"Y\",\"Zr\",\"Nb\",\"Mo\",\"Tc\",\"Ru\",\"Rh\",\"Pd\",\"Ag\",\"Cd\",\"In\",\"Sn\",\"Sb\",\"Te\",\n",
    "              \"I\",\"Xe\",\"Cs\",\"Ba\",\"La\",\"Ce\",\"Pr\",\"Nd\",\"Pm\",\"Sm\",\"Eu\",\"Gd\",\"Tb\",\"Dy\",\"Ho\",\"Er\",\"Tm\",\"Yb\",\"Lu\",\"Hf\",\"Ta\",\"W\",\"Re\",\"Os\",\"Ir\",\n",
    "              \"Pt\",\"Au\",\"Hg\",\"Tl\",\"Pb\",\"Bi\",\"Po\",\"At\",\"Rn\",\"Fr\",\"Ra\",\"Ac\",\"Th\",\"Pa\",\"U\",\"Np\",\"Pu\",\"Am\",\"Cm\"]\n",
    "\n",
    "# validate table correctness\n",
    "validation_element_table = [\"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\", \"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\", \"K\", \"Ca\", \n",
    "                            \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\", \"Rb\", \"Sr\",\"Y\",\n",
    "                            \"Zr\",\"Nb\",\"Mo\",\"Tc\",\"Ru\",\"Rh\",\"Pd\",\"Ag\",\"Cd\",\"In\",\"Sn\",\"Sb\",\"Te\",\"I\",\"Xe\",\"Cs\",\"Ba\",\"La\",\"Ce\",\"Pr\",\"Nd\",\"Pm\",\n",
    "                            \"Sm\",\"Eu\",\"Gd\",\"Tb\",\"Dy\",\"Ho\",\"Er\",\"Tm\",\"Yb\",\"Lu\",\"Hf\",\"Ta\",\"W\",\"Re\",\"Os\",\"Ir\",\"Pt\",\"Au\",\"Hg\",\"Tl\",\"Pb\" ,\"Bi\" ,\n",
    "                            \"Po\" ,\"At\" ,\"Rn\" ,\"Fr\" ,\"Ra\" ,\"Ac\" ,\"Th\" ,\"Pa\" ,\"U\" ,\"Np\" ,\"Pu\" ,\"Am\" ,\"Cm\"]\n",
    "\n",
    "assert(len(element_table) == 96)\n",
    "print(\"NOTE: Correct element table length.\")\n",
    "\n",
    "assert(validation_element_table == element_table)\n",
    "print(\"NOTE: Valid table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823feeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16708, 96])\n",
      "torch.Size([7589, 96])\n",
      "torch.Size([1440, 96])\n",
      "torch.Size([7679, 96])\n",
      "Train Data Size: 15873 | Test Data Size: 835\n",
      "Train Data Size: 7210 | Test Data Size: 379\n",
      "Train Data Size: 1368 | Test Data Size: 72\n",
      "Train Data Size: 7296 | Test Data Size: 383\n"
     ]
    }
   ],
   "source": [
    "returned_datasets = prepare_datasets_for_classes(SUPERCON_DATA_FILE, element_table, 1/20, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3539578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the list into individual variables (if needed)\n",
    "torch_diffusion_data_raw_unconditional_train = returned_datasets[0]\n",
    "torch_diffusion_data_raw_cuprates_train = returned_datasets[1]\n",
    "torch_diffusion_data_raw_pnictides_train = returned_datasets[2]\n",
    "torch_diffusion_data_raw_others_train = returned_datasets[3]\n",
    "\n",
    "torch_diffusion_data_raw_unconditional_test = returned_datasets[4]\n",
    "torch_diffusion_data_raw_cuprates_test = returned_datasets[5]\n",
    "torch_diffusion_data_raw_pnictides_test = returned_datasets[6]\n",
    "torch_diffusion_data_raw_others_test = returned_datasets[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2391f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Using Device: \"cuda:0\" | NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"NOTE: Using Device: \\\"{device}\\\"\",\"|\",(f\"{torch.cuda.get_device_name(0)}\" if torch.cuda.is_available() else \"CPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a397fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_beta_schedule(schedule_name: str, num_diffusion_timesteps: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Get a pre-defined beta schedule for the given name.\n",
    "    Function adapted from https://github.com/openai/improved-diffusion/blob/main/improved_diffusion/gaussian_diffusion.py\n",
    "    Improved support for PyTorch.\n",
    "\n",
    "    :param schedule_name: The name of the beta schedule.\n",
    "    :param num_diffusion_timesteps: The number of diffusion timesteps.\n",
    "    :return: The beta schedule tensor.\n",
    "    :rtype: torch.Tensor[torch.float64]\n",
    "    \"\"\"\n",
    "    if schedule_name == \"linear\":\n",
    "        # Linear schedule from Ho et al, extended to work for any number of diffusion steps.\n",
    "        scale = 1000 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.02\n",
    "        return torch.linspace(\n",
    "            beta_start, beta_end, num_diffusion_timesteps\n",
    "        ).to(torch.float64)\n",
    "    elif schedule_name == \"cosine\":\n",
    "        return betas_for_alpha_bar(\n",
    "            num_diffusion_timesteps,\n",
    "            lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown beta schedule: {schedule_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6110ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def betas_for_alpha_bar(num_diffusion_timesteps: int, alpha_bar: float, max_beta=0.999) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create a beta schedule that discretizes the given alpha_t_bar function,\n",
    "    which defines the cumprod of (1-beta) over time from t = [0,1].\n",
    "    Function adapted from https://github.com/openai/improved-diffusion/blob/main/improved_diffusion/gaussian_diffusion.py\n",
    "    Improved support for PyTorch.\n",
    "\n",
    "    :param num_diffusion_timesteps: The number of betas to produce.\n",
    "    :param alpha_bar: A lambda that takes an argument t from 0 to 1 and produces\n",
    "                      the cumulative product of (1-beta) up to that part of the\n",
    "                      diffusion process.\n",
    "    :param max_beta: The maximum beta to use; use values lower than 1 to prevent\n",
    "                     singularities (Improved Diffusion Paper).\n",
    "    :return: The beta schedule tensor.\n",
    "    :rtype: torch.Tensor[torch.float64]\n",
    "    \"\"\"\n",
    "    betas = []\n",
    "    for i in range(num_diffusion_timesteps):\n",
    "        t1 = i / num_diffusion_timesteps\n",
    "        t2 = (i + 1) / num_diffusion_timesteps\n",
    "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
    "    return torch.Tensor(betas).to(torch.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a67daee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion1D:\n",
    "    \"\"\"\n",
    "    Class for Gaussian diffusion of 1D Tensors (vector diffusion).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sequence_length: int,\n",
    "        timesteps: int,\n",
    "        beta_schedule_type: str\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the GaussianDiffusion1D class.\n",
    "\n",
    "        :param sequence_length: Length of the sequence.\n",
    "        :param timesteps: Number of timesteps.\n",
    "        :param beta_schedule_type: Type of beta schedule. Can be \"linear\" or \"cosine\".\n",
    "\n",
    "        :raises TypeError: If the beta schedule type is unknown.\n",
    "        \"\"\"\n",
    "        self.sequence_length = sequence_length\n",
    "        self.timesteps = timesteps\n",
    "        self.beta_schedule_type = beta_schedule_type\n",
    "\n",
    "        if self.beta_schedule_type == \"linear\":\n",
    "            self.betas = get_named_beta_schedule(self.beta_schedule_type, self.timesteps)\n",
    "        elif self.beta_schedule_type == \"cosine\":\n",
    "            self.betas = get_named_beta_schedule(self.beta_schedule_type, self.timesteps)\n",
    "        else:\n",
    "            raise TypeError(f\"{self.beta_schedule_type} is an unknown beta schedule type.\")\n",
    "\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_bar = torch.cumprod(self.alphas, axis=0)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_0: torch.Tensor,\n",
    "        t: torch.Tensor,\n",
    "        device: str\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward diffusion process. Adding noise ~ N(0, I) to vectors.\n",
    "\n",
    "        :param x_0: Original vector of shape (B, C, L).\n",
    "        :param t: Timestep tensor of shape (B,).\n",
    "        :param device: Device to be used.\n",
    "\n",
    "        :return: Tuple containing mean tensor and noise tensor.\n",
    "        \"\"\"\n",
    "        epsilon = torch.randn_like(x_0)\n",
    "        alphas_bar_t = self.extract(self.alphas_bar, t, x_0.shape)\n",
    "\n",
    "        mean = torch.sqrt(alphas_bar_t).to(device) * x_0.to(device)\n",
    "        variance = torch.sqrt((1 - alphas_bar_t)).to(device) * epsilon.to(device)\n",
    "\n",
    "        return mean + variance, epsilon.to(device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def backward(\n",
    "        self,\n",
    "        x_t: torch.Tensor,\n",
    "        t: torch.Tensor,\n",
    "        model: nn.Module,\n",
    "        **kwargs\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calls the model to predict the noise in the image and returns\n",
    "        the denoised image (x_{t-1}).\n",
    "\n",
    "        This method corresponds to the \"big for loop\" in the sampling algorithm (see algorithm 2 from Ho et al.).\n",
    "\n",
    "        :param x_t: Current image tensor of shape (B, C, L).\n",
    "        :param t: Timestep tensor of shape (B,).\n",
    "        :param model: Model used to predict the noise in the image.\n",
    "        :param **kwargs: Additional arguments to be passed to the model.\n",
    "\n",
    "        :return: Denoised image tensor of shape (B, C, L).\n",
    "        \"\"\"\n",
    "        betas_t = self.extract(self.betas, t, x_t.shape)\n",
    "        sqrt_one_minus_alphas_bar_t = self.extract(torch.sqrt(1. - self.alphas_bar), t, x_t.shape)\n",
    "        sqrt_recip_alphas_t = self.extract(torch.sqrt(1.0 / self.alphas), t, x_t.shape)\n",
    "        mean = sqrt_recip_alphas_t * (x_t - ((betas_t / sqrt_one_minus_alphas_bar_t) * model(x_t, t, **kwargs)))\n",
    "        posterior_variance_t = betas_t\n",
    "\n",
    "        # Applies noise to this image if we are not in the last step yet.\n",
    "        if t == 0:\n",
    "            return mean\n",
    "        else:\n",
    "            z = torch.randn_like(x_t)\n",
    "            variance = torch.sqrt(posterior_variance_t) * z\n",
    "            return mean + variance\n",
    "\n",
    "    @staticmethod\n",
    "    def extract(\n",
    "        values: torch.Tensor,\n",
    "        t: torch.Tensor,\n",
    "        x_0_shape: Tuple[int]\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Picks the values from `values` according to the indices stored in `t`.\n",
    "\n",
    "        :param values: Tensor of values to pick from.\n",
    "        :param t: Index tensor.\n",
    "        :param x_0_shape: Shape of the original tensor x_0.\n",
    "\n",
    "        :return: Reshaped tensor with picked values.\n",
    "        \"\"\"\n",
    "        batch_size = t.shape[0]\n",
    "        vector_to_reshape = values.gather(-1, t.cpu())\n",
    "        \"\"\"\n",
    "        if len(x_shape) - 1 = 2:\n",
    "        reshape `out` to dims\n",
    "        (batch_size, 1, 1)\n",
    "        \"\"\"\n",
    "        return vector_to_reshape.reshape(batch_size, *((1,) * (len(x_0_shape) - 1))).to(t.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97416d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_distribution(noise: torch.Tensor, predicted_noise: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Plot noise distributions to visualize and compare predicted and ground truth noise.\n",
    "    \"\"\"\n",
    "    plt.hist(noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"ground truth noise\")\n",
    "    plt.hist(predicted_noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"predicted noise\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ecb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFFUSION_TIMESTEPS = 1000\n",
    "diffusion_model = GaussianDiffusion1D(96, DIFFUSION_TIMESTEPS, \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd9c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 24 # TODO: test different values - change much bigger actually uses CPU (change to like 12)\n",
    "NO_EPOCHS = 100\n",
    "PRINT_FREQUENCY = 10\n",
    "LR = 1e-4\n",
    "VERBOSE = True\n",
    "USE_VALIDATION_SET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c49e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_dataset_train = TensorDataset(torch_diffusion_data_raw_unconditional_train)\n",
    "train_dataloader = DataLoader(diffusion_dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "\n",
    "if USE_VALIDATION_SET == True:\n",
    "    diffusion_dataset_test = TensorDataset(torch_diffusion_data_raw_unconditional_test)\n",
    "    test_dataloader = DataLoader(diffusion_dataset_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ce9498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet1D(\n",
    "    dim = 48,\n",
    "    dim_mults = (1, 2, 3, 6),\n",
    "    channels = 1\n",
    ")\n",
    "unet.to(device)\n",
    "\n",
    "optimizer = torch.optim.NAdam(unet.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Training Loop\n",
    "training_steps_tracker = []\n",
    "loss_tracker_train = [] # to plot train loss/training step - make sure outside for loop\n",
    "loss_tracker_val = [] # to plot val loss/training step - make sure outside for loop\n",
    "epoch_tracker = []\n",
    "loss_tracker_train_epoch = [] # to plot train loss/epoch - make sure outside for loop\n",
    "loss_tracker_val_epoch = [] # to plot val loss/epoch - make sure outside for loop\n",
    "for epoch in range(NO_EPOCHS):\n",
    "    mean_epoch_loss_train = [] # put in for loop - wipe clean each time\n",
    "    mean_epoch_loss_val = [] # put in for loop - wipe clean each time\n",
    "    \n",
    "    # on train dataset\n",
    "    for batch in train_dataloader:\n",
    "        t = torch.randint(0, diffusion_model.timesteps, (BATCH_SIZE,)).long().to(device)\n",
    "        batch_train = batch[0].unsqueeze(1).to(device)\n",
    "        \n",
    "        noisy_batch_train, gt_noise_train = diffusion_model.forward(batch_train, t, device) \n",
    "        predicted_noise_train = unet(noisy_batch_train.to(torch.float32), t)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # loss(pred, target)\n",
    "        loss = torch.nn.functional.mse_loss(predicted_noise_train, gt_noise_train)\n",
    "        loss_tracker_train.append(loss.item())\n",
    "        training_steps_tracker.append(1)\n",
    "        mean_epoch_loss_train.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if USE_VALIDATION_SET == True:\n",
    "        # on test dataset\n",
    "        for batch in test_dataloader:\n",
    "            t = torch.randint(0, diffusion_model.timesteps, (BATCH_SIZE,)).long().to(device)\n",
    "            batch_val = batch[0].unsqueeze(1).to(device)\n",
    "\n",
    "            noisy_batch_val, gt_noise_val = diffusion_model.forward(batch_val, t, device) \n",
    "            predicted_noise_val = unet(noisy_batch_val.to(torch.float32), t)\n",
    "\n",
    "            loss = torch.nn.functional.mse_loss(predicted_noise_val, gt_noise_val)\n",
    "            loss_tracker_train.append(loss.item())\n",
    "            mean_epoch_loss_val.append(loss.item())\n",
    "    \n",
    "    epoch_tracker.append(epoch)\n",
    "    loss_tracker_train_epoch.append(np.mean(mean_epoch_loss_train))\n",
    "    if USE_VALIDATION_SET == True:\n",
    "        loss_tracker_val_epoch.append(np.mean(mean_epoch_loss_val))\n",
    "    \n",
    "    # print loss(s)\n",
    "    if epoch == 0 or epoch % PRINT_FREQUENCY == 9:\n",
    "        print('---')\n",
    "        if USE_VALIDATION_SET == True:\n",
    "            print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss_train)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n",
    "        else:\n",
    "            print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss_train)}\")\n",
    "        if VERBOSE:\n",
    "            with torch.no_grad():\n",
    "                plot_noise_distribution(gt_noise_train, predicted_noise_train)\n",
    "                if USE_VALIDATION_SET == True:\n",
    "                    plot_noise_distribution(gt_noise_val, predicted_noise_val)\n",
    "        \n",
    "        torch.save(unet.state_dict(), f\"everything5_unet_param_{epoch}.pth\") # save UNet states - use lowest loss UNet for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59032cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss(s) vs training steps\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "training_steps_tracker_sum = list(range(len(training_steps_tracker))/1000)\n",
    "plt.plot(training_steps_tracker_sum, loss_tracker_train, label='Training Loss')\n",
    "# plt.plot(epochs, loss_tracker_val, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training Loss vs Training Steps')\n",
    "plt.xlabel('Training Steps (1e3)')\n",
    "plt.ylabel('Training Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "# plt.xticks(arange(0, len(loss_tracker_train) + 1, 100))\n",
    " \n",
    "# # Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss(s) vs epochs\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epoch_tracker, loss_tracker_train_epoch, label='Training Loss')\n",
    "# plt.plot(epochs, loss_tracker_val, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "# plt.xticks(arange(0, len(loss_tracker_train) + 1, 100))\n",
    " \n",
    "# # Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0bc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38333cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LATER\n",
    "unet = Unet1D(\n",
    "    dim = 48,\n",
    "    dim_mults = (1, 2, 3, 6),\n",
    "    channels = 1\n",
    ")\n",
    "unet.to(device)\n",
    "unet.load_state_dict(torch.load((\"everything5_unet_param_79.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c881fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLE_VECTORS = 500000\n",
    "MAX_ON_GPU = 10000\n",
    "VERBOSE_SAMPLING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "502edad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "TOTAL SAMPLE: 500000 COMPOUNDS\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([10000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([20000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([30000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([40000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([50000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([60000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([70000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([80000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([90000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([100000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([110000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([120000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([130000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([140000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([150000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([160000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([170000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([180000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([190000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([200000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([210000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([220000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([230000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([240000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([250000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([260000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([270000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([280000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([290000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([300000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([310000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([320000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([330000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([340000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([350000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([360000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([370000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([380000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([390000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([400000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([410000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([420000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([430000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([440000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([450000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([460000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([470000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([480000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([490000, 1, 96])\n",
      "torch.Size([10000, 1, 96])\n",
      "t = 999\n",
      "t = 949\n",
      "t = 899\n",
      "t = 849\n",
      "t = 799\n",
      "t = 749\n",
      "t = 699\n",
      "t = 649\n",
      "t = 599\n",
      "t = 549\n",
      "t = 499\n",
      "t = 449\n",
      "t = 399\n",
      "t = 349\n",
      "t = 299\n",
      "t = 249\n",
      "t = 199\n",
      "t = 149\n",
      "t = 99\n",
      "t = 49\n",
      "t = 0\n",
      "Sampling Complete.\n",
      "total size: torch.Size([500000, 1, 96])\n",
      "CPU times: total: 9h 51min 17s\n",
      "Wall time: 9h 52min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# torch.manual_seed(16) # for replication\n",
    "\n",
    "total_generated_output = torch.empty((0,)).to(device) # ensure that on same device as \"vectors\"\n",
    "print(total_generated_output.device.type) # ensure that on same device as \"vectors\"\n",
    "print(f\"TOTAL SAMPLE: {NUM_SAMPLE_VECTORS} COMPOUNDS\")\n",
    "\n",
    "assert(NUM_SAMPLE_VECTORS%MAX_ON_GPU == 0)\n",
    "\n",
    "for j in range(int(NUM_SAMPLE_VECTORS/MAX_ON_GPU)):\n",
    "    with torch.no_grad():\n",
    "        vectors = torch.randn(MAX_ON_GPU, 1, diffusion_model.sequence_length).to(device)\n",
    "        print(vectors.size())\n",
    "        \"\"\"\n",
    "        Sampling Algorithm (Algorithm 2 from Ho et al.). \n",
    "\n",
    "        \"taking noise and turning into good stuff\"\n",
    "        \"\"\"\n",
    "        for i in reversed(range(diffusion_model.timesteps)):\n",
    "            t = torch.full((1,), i, dtype=torch.long, device=device)\n",
    "            vectors = diffusion_model.backward(vectors.to(torch.float32), t, unet.eval().to(device))\n",
    "            if (VERBOSE_SAMPLING == True) and (i % 50 == 49 or i == diffusion_model.timesteps - 1):\n",
    "                print(f\"t = {i}\")\n",
    "                # print(torch.round(vectors[0], decimals = 2))\n",
    "                # torch.set_printoptions(precision=2)\n",
    "            if i == 0:\n",
    "                print(\"t = 0\")\n",
    "                print(\"Sampling Complete.\")\n",
    "        \n",
    "        # concatenate to total_generated_output\n",
    "        total_generated_output = torch.cat((total_generated_output, vectors), 0)\n",
    "        print(f\"total size: {total_generated_output.size()}\")\n",
    "#         print(f\"percent done: {(float(total_generated_output.size())/NUM_SAMPLE_VECTORS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bf2e935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded 72361 faulty samples.\n",
      "CPU times: total: 1h 10min 34s\n",
      "Wall time: 1h 11min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total_generated_output = total_generated_output.squeeze()\n",
    "total_generated_output = total_generated_output.unsqueeze(1)\n",
    "\n",
    "SHOW_FAULTY_GENERATIONS = False\n",
    "VERBOSE_GENERATION_PRINTING = False\n",
    "faulty_sample_count = []\n",
    "generated_superconductors_raw = []\n",
    "for i in range(int(NUM_SAMPLE_VECTORS)):\n",
    "    raw_generated_vector = torch.round(total_generated_output[i], decimals = 2)\n",
    "    raw_generated_vector = raw_generated_vector[0]\n",
    "\n",
    "    \"\"\"\n",
    "    Apply threshold filter to remove residual noise.\n",
    "    \"\"\"\n",
    "    # TODO: refine threshold method\n",
    "    filtered_generated_vector = raw_generated_vector\n",
    "    threshold = 0.08# Threshold value - keep between [0.01, 0.1]\n",
    "    mask = torch.abs(filtered_generated_vector) < threshold # Create a mask for values that satisfy the condition\n",
    "    filtered_generated_vector[mask] = 0.00 # Apply the mask to set the values to 0.00\n",
    "\n",
    "    torch.set_printoptions(precision=2)\n",
    "\n",
    "    \"\"\"\n",
    "    Get rid of result if has negative element values <-0.1. Too much noise.\n",
    "    \"\"\"\n",
    "    # TODO: if samples with neg values are very noise, examine training process, change timesteps and epochs.\n",
    "    negative_values_mask = filtered_generated_vector < 0.0 # after mask\n",
    "    if (True not in negative_values_mask) and (1 < torch.count_nonzero(filtered_generated_vector) < 8):\n",
    "        sample_faulty = False\n",
    "        generated_cform = cform_from_vector(filtered_generated_vector, element_table)\n",
    "        if VERBOSE_GENERATION_PRINTING == True:\n",
    "            print(generated_cform)\n",
    "        generated_superconductors_raw.append(generated_cform)\n",
    "    else:\n",
    "        sample_faulty = True\n",
    "        faulty_sample_count.append(1)\n",
    "        if SHOW_FAULTY_GENERATIONS == True:\n",
    "            generated_cform = cform_from_vector(filtered_generated_vector, element_table)\n",
    "            print(f\"Faulty Generation: {generated_cform}\")\n",
    "\n",
    "print(f\"Excluded {len(faulty_sample_count)} faulty samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95a423fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_superconductors_raw = np.array(generated_superconductors_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59ddb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_superconductors_vector_formulas = []\n",
    "for i in range(np.size(generated_superconductors_raw)):\n",
    "    split_formula_char = split_scform_to_char(generated_superconductors_raw[i])\n",
    "    merge_formula_char = merge_sc_char(split_formula_char)\n",
    "    vector_formula = split_sc_to_vector(merge_formula_char, element_table)\n",
    "    generated_superconductors_vector_formulas.append(vector_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c419b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_superconductors_vector_formulas = np.array(generated_superconductors_vector_formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9c5b79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping Vectors:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Repeating Vectors:\n",
      "[[0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " [0.   0.   0.   ... 0.   0.   0.  ]\n",
      " ...\n",
      " [0.   0.   1.03 ... 0.   0.   0.  ]\n",
      " [0.13 0.   0.   ... 0.   0.   0.  ]\n",
      " [0.3  0.   0.   ... 0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# uniqueness and novelty test\n",
    "# find overlap between training data and generated data\n",
    "overlap = []\n",
    "for vec1 in generated_superconductors_vector_formulas:\n",
    "    for vec2 in torch_diffusion_data_raw_pnictides_train.numpy():\n",
    "        if np.all(np.equal(vec1, vec2)):\n",
    "            overlap.append(vec1)\n",
    "\n",
    "overlap = np.array(overlap)\n",
    "\n",
    "# Find repeating vectors and their counts\n",
    "unique_vectors, counts = np.unique(generated_superconductors_vector_formulas, axis=0, return_counts=True)\n",
    "\n",
    "# Get the repeating vectors\n",
    "repeating_vectors = unique_vectors[counts > 1]\n",
    "\n",
    "print(\"Overlapping Vectors:\")\n",
    "print(overlap)\n",
    "print(\"Repeating Vectors:\")\n",
    "print(repeating_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e10ef9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3411\n"
     ]
    }
   ],
   "source": [
    "print(np.size(repeating_vectors, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a038847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.size(overlap, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12d9a74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samuel Yuan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymatgen\\core\\periodic_table.py:221: UserWarning: No Pauling electronegativity for Ar. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Yuan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymatgen\\core\\periodic_table.py:221: UserWarning: No Pauling electronegativity for Ne. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Samuel Yuan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymatgen\\core\\periodic_table.py:221: UserWarning: No Pauling electronegativity for He. Setting to NaN. This has no physical meaning, and is mainly done to avoid errors caused by the code expecting a float.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79828\n"
     ]
    }
   ],
   "source": [
    "valid_generated_compounds, valid_generated_compounds_size = filter_for_valid_generated_compounds(generated_superconductors_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca422c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array has been successfully saved to CSV file.\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILE = \"final_everything_1.csv\"\n",
    "store_valid_to_csv(valid_generated_compounds, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865c745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e5cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
